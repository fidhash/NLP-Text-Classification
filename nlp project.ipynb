{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696a087c",
   "metadata": {},
   "source": [
    "# 1. Loading and Preprocessing\n",
    "Load the dataset and perform necessary preprocessing steps. This should include text cleaning, tokenization, and removal of stopwords. Explain the preprocessing techniques used and their impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3aed7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('C:/Users/Asus/Downloads/nlp_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387ab160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>i begun to feel distressed for you</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>i left feeling annoyed and angry thinking that...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>i were to ever get married i d have everything...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>i feel reluctant in applying there because i w...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>i just wanted to apologize to you because i fe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5937 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "0     i seriously hate one subject to death but now ...    fear\n",
       "1                    im so full of life i feel appalled   anger\n",
       "2     i sit here to write i start to dig out my feel...    fear\n",
       "3     ive been really angry with r and i feel like a...     joy\n",
       "4     i feel suspicious if there is no one outside l...    fear\n",
       "...                                                 ...     ...\n",
       "5932                 i begun to feel distressed for you    fear\n",
       "5933  i left feeling annoyed and angry thinking that...   anger\n",
       "5934  i were to ever get married i d have everything...     joy\n",
       "5935  i feel reluctant in applying there because i w...    fear\n",
       "5936  i just wanted to apologize to you because i fe...   anger\n",
       "\n",
       "[5937 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2334de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fear', 'anger', 'joy'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Emotion\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efbaf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=data['Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494546e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'\\s+', ' ', text) \n",
    "    return text\n",
    "\n",
    "data['cleaned_text'] = data['Comment'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986f3f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [i, seriously, hate, one, subject, to, death, ...\n",
       "1             [im, so, full, of, life, i, feel, appalled]\n",
       "2       [i, sit, here, to, write, i, start, to, dig, o...\n",
       "3       [ive, been, really, angry, with, r, and, i, fe...\n",
       "4       [i, feel, suspicious, if, there, is, no, one, ...\n",
       "                              ...                        \n",
       "5932           [i, begun, to, feel, distressed, for, you]\n",
       "5933    [i, left, feeling, annoyed, and, angry, thinki...\n",
       "5934    [i, were, to, ever, get, married, i, d, have, ...\n",
       "5935    [i, feel, reluctant, in, applying, there, beca...\n",
       "5936    [i, just, wanted, to, apologize, to, you, beca...\n",
       "Name: tokens, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "data['tokens'] = data['cleaned_text'].apply(word_tokenize)\n",
    "data['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e36433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c6520",
   "metadata": {},
   "source": [
    "Preprocessing makes the text clearer and easier for the model to understand, helping it focus on the words that matter.\n",
    "1.Cleaning reduces noise:\n",
    "Cleaning removes unnecessary characters like punctuation and converts text to lowercase. This helps the model focus on important words without getting confused by irrelevant details.\n",
    "Tokenization breaks text into words:\n",
    "2.Tokenization splits the text into individual words (tokens), making it easier to analyze word patterns and frequencies.\n",
    "3.Removing stopwords improves focus:\n",
    "Stopwords like \"the\" and \"is\" are common but don't add much meaning. Removing them helps the model focus on more important words, improving accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb375067",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction:\n",
    "Implement feature extraction using CountVectorizer or TfidfVectorizer. Describe how the chosen method transforms the text data into numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ab9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab96f1",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency) is an advanced technique used to evaluate the importance of a word in a document relative to a collection of documents. Unlike Bag of Words, which only considers the frequency of words, TF-IDF also considers how common or rare a word is across all documents, making it more effective for tasks like text classification and information retrieval. Term Frequency (TF) is a method which measures how frequently a term appears in a document.The higher the frequencythe more important the word is in that document. Inverse Document Frequency (IDF) is a method which measures how important a term is across the entire set of documents.The less frequent the term across all documents, the higher its IDF value, meaning it carries more significance. How TfidfVectorizer Works: 1.Tokenization: Splits the text into individual terms (words or tokens). 2.Calculation of TF: Calculates the frequency of each term in a document. 3.Calculation of IDF: Computes the inverse document frequency for each term across all documents. 4.TF-IDF Matrix: Multiplies the TF and IDF values for each term, creating a matrix where each row corresponds to a document and each column to a term, with values representing the TF-IDF score. In general, TfidfVectorizer is often preferred for most NLP tasks due to its ability to provide a more nuanced representation of text data by considering both term frequency and document frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9720e2",
   "metadata": {},
   "source": [
    "# 3. Model Development:\n",
    "Train the following machine learning models\n",
    "a)Naive Bayesb)Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d0c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00851507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2913e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(kernel='linear')\n",
    "model_svm.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3e5fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce12e8a",
   "metadata": {},
   "source": [
    "# 4. Model Comparison\n",
    "Evaluate the model using appropriate metrics (e.g., accuracy, F1-score). Provide a brief explanation of the chosen model and its suitability for emotion classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4b23da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Accuracy: 0.984006734006734, F1-Score: 0.9840173067226208\n",
      "SVM - Accuracy: 0.9915824915824916, F1-Score: 0.9915838847398599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "print(f'Naive Bayes - Accuracy: {accuracy_nb}, F1-Score: {f1_nb}')\n",
    "print(f'SVM - Accuracy: {accuracy_svm}, F1-Score: {f1_svm}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c3eb9",
   "metadata": {},
   "source": [
    "Model Comparison\n",
    "Metrics Used:\n",
    "1.Accuracy: Measures how many predictions are correct out of the total.\n",
    "2.F1-Score: Balances precision and recall, useful for uneven class distribution.\n",
    "\n",
    "After training both models (Naive Bayes and SVM), we compare their performance using accuracy and F1-score on the test data.\n",
    "Naive Bayes works well with text classification, especially with smaller datasets. Fast and efficient for high-dimensional data.\n",
    "Support Vector Machine (SVM) handles complex classification boundaries well and often yields higher accuracy for text data.\n",
    "Naive Bayes is faster but less accurate, while SVM generally performs better with more complex text datasets, making it the preferred choice for emotion classification when accuracy is crucial.In this dataset,after evaluation Naive Bayes has an accuracy of 0.98 and F1-Score is 0.98 and SVM has an accuracy of 0.99 and F1-Score is 0.99.This indicates that SVM may be better at capturing more complex relationships in the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
